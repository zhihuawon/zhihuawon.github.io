---
layout: post
title: 深度神经网络课程资料-Geoffrey E. Hinton
categories: [machine learning]
tags: [Geoffrey Hinton, Deep Learning]
description: Hinton于2006年在science杂志上发表文章“Reducing the dimensionality of data with neural networks”，从而掀起了深度学习的热潮。Hinton孜孜不倦的从事神经网络的研究几十载，是深度学习的开山鼻祖。此分享为Hinton在Coursera上的授课视频，供大家参考学习，请勿用于商业用途，谢谢~
---
<p>Hinton于2006年在science杂志上发表文章“Reducing the dimensionality of data with neural networks”，从而掀起了深度学习的热潮。Hinton孜孜不倦的从事神经网络的研究几十载，是深度学习的开山鼻祖。此分享为Hinton在Coursera上的授课视频，供大家参考学习，请勿用于商业用途，谢谢~</p>
<div id="div4"><h3>Geoffrey Hinton</h3></div>
<p>Geoffrey Hinton is a British-born cognitive psychologist and computer scientist, most noted for his work on artificial neural networks. He now divides his time working for Google and University of Toronto. He is the co-inventor of the backpropagation and contrastive divergence training algorithms and is an important figure in the deep learning movement.</p>
<div id="div4"><h3>Syllabus</h3>
	<li>Lecture 1: Introduction</li>
	<li>Lecture 2: The Perceptron learning procedure</li>
	<li>Lecture 3: The backpropagation learning proccedure</li>
	<li>Lecture 4: Learning feature vectors for words</li>
	<li>Lecture 5: Object recognition with neural nets</li>
	<li>Lecture 6: Optimization: How to make the learning go faster</li>
	<li>Lecture 7: Recurrent neural networks</li>
	<li>Lecture 8: More recurrent neural networks</li>
	<li>Lecture 9: Ways to make neural networks generalize better</li>
	<li>Lecture 10: Combining multiple neural networks to improve generalization</li>
	<li>Lecture 11: Hopfield nets and Boltzmann machines</li>
	<li>Lecture 12: Restricted Boltzmann machines (RBMs)</li>
	<li>Lecture 13: Stacking RBMs to make Deep Belief Nets</li>
	<li>Lecture 14: Deep neural nets with generative pre-training</li>
	<li>Lecture 15: Modeling hierarchical structure with neural nets</li>
	<li>Lecture 16: Recent applications of deep neural nets</li>
</div>
<div id="div4"><h3>Download</h3></div>
<div id="div5">
	<li>资料正在整理中，急需请email至zhihuawon@gmail.com</li>
</div>
